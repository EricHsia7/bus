{"version":3,"file":"645.0cc49e6239a579072d9a.js","mappings":"4oCA2BA,SAASA,EAAqBC,GAC5B,IAAAC,EAAoB,CAClB,CAAC,KAAM,SACP,CAAC,KAAM,YACP,CAAC,KAAM,aACP,CAAC,KAAM,aACP,CAAC,KAAM,aACP,CAAC,KAAM,aACP,CAAC,KAAM,aACP,CAAC,QAAS,oBACV,CAAC,OAAQ,eACT,CAAC,KAAM,gBACP,CAAC,KAAM,gBACP,CAAC,MAAO,WACR,CAAC,MAAO,WACR,CAAC,MAAO,YACRD,IAAU,CAAC,KAAM,UAASE,GAAAC,EAAAA,EAAAA,GAAAF,EAAA,GAK5B,MAJe,CACbG,KAjBSF,EAAA,GAkBTG,IAlBcH,EAAA,GAqBlB,CAEO,SAAeI,IAAuB,OAAAC,EAAAC,MAAC,KAADC,UAAA,CA4C5C,SAAAF,IAAA,OAAAA,GAAAG,EAAAA,EAAAA,GA5CM,YAKL,IAJA,IAAIC,EAA2B,EACzBC,EAAmD,CAAC,EACpDC,GAAeC,EAAAA,EAAAA,MAEZC,EAAI,EAAGA,EAAIF,EAAcE,IAAK,CACrC,IAEiCC,EAD7BC,EAA+B,EAAEC,EAAAC,QADXC,EAAAA,EAAAA,IAAeL,IAER,IAAjC,IAAAG,EAAAG,MAAAL,EAAAE,EAAAI,KAAAC,MAAmC,KAAxBC,EAAOR,EAAAS,MACVC,QAAaC,EAAAA,EAAAA,IAAUZ,EAAGS,GAE1BI,EADeC,OAAOH,GACII,OAASN,EAAQM,OACjDnB,GAAoBiB,EACpBX,GAAwBW,CAC1B,CAAC,OAAAG,GAAAb,EAAAc,EAAAD,EAAA,SAAAb,EAAAe,GAAA,CACD,IAAMC,EAAenC,EAAqBgB,GACpCoB,EAAkBD,EAAa7B,IAChCO,EAAwBwB,eAAeD,KAC1CvB,EAAwBuB,GAAmB,CACzCE,SAAUH,EACVI,KAAM,IAGV1B,EAAwBsB,EAAa7B,KAAKiC,MAAQrB,CACpD,CAEA,IAAMsB,GAAYC,EAAAA,EAAAA,IAAa7B,GAEzB8B,EAAqC,CAAC,EAC5C,IAAK,IAAMpC,KAAOO,EAAyB,CACzC,IAAMsB,EAAetB,EAAwBP,GAAKgC,SAC5CK,EAAmB9B,EAAwBP,GAAKiC,KACtDG,EAAiBpC,GAAO,CACtBgC,SAAUH,EACVI,MAAME,EAAAA,EAAAA,IAAaE,GAEvB,CAOA,MALoC,CAClCH,UAAAA,EACAE,iBAAAA,EAIJ,IAACjC,MAAA,KAAAC,UAAA,C,yEC7DD,IAWMkC,EAAoD,GAyO1D,IACIC,EADEC,EAA+B,CAAC,EAItC,GAA4B,oBAAjBC,aAA8B,CACvC,IAAMC,EAA4B,IAAID,aAAa,IAAIE,IAAmD,qBAC1GJ,EAAOG,EAA0BH,MAC5BK,OACP,KAAO,CACL,IAAMC,EAAsB,IAAIC,OAAO,IAAIH,IAAmD,oBAC9FJ,EAAOM,CACT,CAgBO,SAAeE,IAAa,OAAAC,EAAA7C,MAAC,KAADC,UAAA,CAelC,SAAA4C,IAAA,OAAAA,GAAA3C,EAAAA,EAAAA,GAfM,YACL,IA9CM4C,EA8CAC,QA9CAD,GADM,IAAIE,MAAOC,UACE,MAClBd,EAAsBe,OAAO,SAAChC,GAAI,OAAKA,EAAKiC,UAAYL,CAAU,IA8CnEM,GAASC,EAAAA,EAAAA,MAYf,aAVqB,IAAIC,QAAQ,SAACC,EAASC,GACzCnB,EAA6Be,GAAUG,EAEvCnB,EAAKqB,QAAU,SAAUjC,GACvBgC,EAAOhC,EAAEkC,QACX,EAEAtB,EAAKuB,YAAY,CAACZ,EAAYK,GAChC,EAGF,IAACpD,MAAA,KAAAC,UAAA,CA5BDmC,EAAKwB,UAAY,SAAUpC,GACzB,IAAAqC,GAAAlE,EAAAA,EAAAA,GAAyB6B,EAAEsC,KAAI,GAAxBC,EAAMF,EAAA,GAAET,EAAMS,EAAA,GACjBxB,EAA6Be,KAC/Bf,EAA6Be,GAAQW,UAC9B1B,EAA6Be,GAExC,EAGAhB,EAAKqB,QAAU,SAAUjC,GAEzB,C,olCCvSA,IA6CIwC,EADEC,EAAwC,CAAC,EAI/C,GAA4B,oBAAjB3B,aAA8B,CACvC,IAAM4B,EAAmC,IAAI5B,aAAa,IAAIE,IAAgE,qBAC9HwB,EAAiCE,EAAiC9B,MACnCK,OACjC,KAAO,CACL,IAAMyB,EAAmC,IAAIvB,OAAO,IAAIH,IAAgE,oBACxHwB,EAAiCE,CACnC,CAqKC,SAAAC,IAAA,OAAAA,GAAAjE,EAAAA,EAAAA,GAXM,YACL,IAEsBkE,EADhBL,EAAuC,GAAGM,EAAA1D,QAD7BC,EAAAA,EAAAA,IAAe,IAEZ,IAAtB,IAAAyD,EAAAxD,MAAAuD,EAAAC,EAAAvD,KAAAC,MAAwB,KAAblB,EAAGuE,EAAAnD,MACNqD,QAAanD,EAAAA,EAAAA,IAAU,EAAGtB,GAChC,GAAIyE,EAAM,CACR,IAAMC,EAASC,KAAKC,MAAMH,GAC1BP,EAAOW,KAAKH,EACd,CACF,CAAC,OAAAhD,GAAA8C,EAAA7C,EAAAD,EAAA,SAAA8C,EAAA5C,GAAA,CACD,OAAOsC,CACT,IAAC/D,MAAA,KAAAC,UAAA,CAlKD+D,EAA+BJ,UAAY,SAAUpC,GACnD,IAAAqC,GAAAlE,EAAAA,EAAAA,GAAyB6B,EAAEsC,KAAI,GAAxBC,EAAMF,EAAA,GAAET,EAAMS,EAAA,GACjBI,EAAsCb,KACxCa,EAAsCb,GAAQW,UACvCE,EAAsCb,GAEjD,EAGAY,EAA+BP,QAAU,SAAUjC,GAEnD,EAyJA,IACImD,EADEC,EAAoC,CAAC,EAI3C,GAA4B,oBAAjBtC,aAA8B,CACvC,IAAMC,EAA4B,IAAID,aAAa,IAAIE,IAAI,qBAC3DmC,EAAyBpC,EAA0BH,MAC5BK,OACzB,KAAO,CACL,IAAMC,EAAsB,IAAIC,OAAO,IAAIH,IAAI,oBAC/CmC,EAAyBjC,CAC3B,CAgBO,SAAemC,EAAkBC,EAAAC,GAAA,OAAAC,EAAAhF,MAAC,KAADC,UAAA,CAcvC,SAAA+E,IAAA,OAAAA,GAAA9E,EAAAA,EAAAA,GAdM,UAAkC+E,EAAoBC,GAC3D,IAAM9B,GAASC,EAAAA,EAAAA,MAET8B,QAA0BC,EAAAA,EAAAA,MAC1BC,QA5CD,WAA2C,OAAAlB,EAAAnE,MAAC,KAADC,UAAA,CA4CTqF,GASvC,aAPqB,IAAIhC,QAAQ,SAACC,EAASC,GACzCoB,EAAkCxB,GAAUG,EAC5CoB,EAAuBlB,QAAU,SAAUjC,GACzCgC,EAAOhC,EAAEkC,QACX,EACAiB,EAAuBhB,YAAY,CAACwB,EAAmBE,EAA0BJ,EAAYC,EAAa9B,GAC5G,EAEF,GAAC4B,EAAAhF,MAAA,KAAAC,UAAA,CA3BD0E,EAAuBf,UAAY,SAAUpC,GAC3C,IAAA+D,GAAA5F,EAAAA,EAAAA,GAAyB6B,EAAEsC,KAAI,GAAxBC,EAAMwB,EAAA,GAAEnC,EAAMmC,EAAA,GACjBX,EAAkCxB,KACpCwB,EAAkCxB,GAAQW,UACnCa,EAAkCxB,GAE7C,EAGAuB,EAAuBlB,QAAU,SAAUjC,GAE3C,C,0ECpOO,SAAegE,EAAeC,EAAAC,GAAA,OAAAC,EAAA3F,MAAC,KAADC,UAAA,CA+BpC,SAAA0F,IAAA,OAAAA,GAAAzF,EAAAA,EAAAA,GA/BM,UAA+B0F,EAAuBC,GAC3D,IAAMhG,EAAM,MAAKiG,EAAAA,EAAAA,IAAaD,EAAM,gBAG9BE,EAAgB,GAFRF,EAAKG,WACHH,EAAKI,aAEfC,QAAwC/E,EAAAA,EAAAA,IAAU,EAAGtB,GAC3D,GAAIqG,EAAiC,CACnC,IAAMC,EAAoC3B,KAAKC,MAAMyB,GACrDC,EAAkCC,MAAMC,KAAOT,EAC/CO,EAAkCrC,KAAKiC,IAAUH,EACjD,IAAMU,EAAcH,EAAkCrC,KAAKiC,GACvDO,EAAcH,EAAkCC,MAAMG,MACxDJ,EAAkCC,MAAMG,IAAMD,GAE5CA,EAAcH,EAAkCC,MAAMI,MACxDL,EAAkCC,MAAMI,IAAMF,SAE1CG,EAAAA,EAAAA,IAAU,EAAG5G,EAAK2E,KAAKkC,UAAUP,GACzC,KAAO,CACL,IAAMQ,EAAyB,CAAC,EAC1B7C,EAAO,IAAI8C,YAAY,MAC7B9C,EAAKiC,IAAUH,EACfe,EAAuB7C,KAAO+C,MAAMC,KAAKhD,GACzC6C,EAAuBP,MAAQ,CAC7BC,IAAKT,EACLW,IAAKX,EACLY,IAAK,GAEPG,EAAuBd,KAAO,CAACA,EAAKkB,cAAelB,EAAKmB,WAAa,EAAGnB,EAAKoB,iBACvER,EAAAA,EAAAA,IAAU,EAAG5G,EAAK2E,KAAKkC,UAAUC,GACzC,CACF,IAAC3G,MAAA,KAAAC,UAAA,CA+BA,SAAAiH,IAAA,OAAAA,GAAAhH,EAAAA,EAAAA,GA7BM,YACL,IAAMiH,EAAU,IAAInE,KACpBmE,EAAQC,SAAS,GACjBD,EAAQE,WAAW,GACnBF,EAAQG,WAAW,GACnBH,EAAQI,gBAAgB,GAGxB,IAFA,IAAMC,GAAYC,EAAAA,EAAAA,IAAWN,GAAS,EAAsB,EAAG,GACzDpD,EAAmC,GAChCxD,EAAI,EAAGA,GA3Ca,EA2CSA,IAAK,CACzC,IAAMsF,GAAO4B,EAAAA,EAAAA,IAAWD,EAAWjH,EAAG,EAAG,GACnCV,EAAM,MAAKiG,EAAAA,EAAAA,IAAaD,EAAM,gBAC9BK,QAAwC/E,EAAAA,EAAAA,IAAU,EAAGtB,GAC3D,GAAIqG,EAAiC,CACnC,IAAMC,EAAoC3B,KAAKC,MAAMyB,GACrDnC,EAAOW,KAAKyB,EACd,KAAO,CACL,IAAMuB,EAA2B,CAAC,EAC5B5D,EAAO,IAAI8C,YAAY,MAC7Bc,EAAyB5D,KAAO+C,MAAMC,KAAKhD,GAC3C4D,EAAyBtB,MAAQ,CAC/BC,IAAK,EACLE,IAAK,EACLC,IAAK,GAEPkB,EAAyB7B,KAAO,CAACA,EAAKkB,cAAelB,EAAKmB,WAAa,EAAGnB,EAAKoB,WAC/ElD,EAAOW,KAAKgD,EACd,CACF,CACA,OAAO3D,CACT,IAAC/D,MAAA,KAAAC,UAAA,CAiBM,SAAe0H,EAAiB7C,EAAAC,EAAA6C,GAAA,OAAAC,EAAA7H,MAAC,KAADC,UAAA,CAgBtC,SAAA4H,IAAA,OAAAA,GAAA3H,EAAAA,EAAAA,GAhBM,UAAiC4H,EAAeC,EAAgBC,GACrE,IAAMC,EAAS,IAAItF,OAAO,IAAIH,IAAuD,oBAC/E0F,QAhDD,WAAuC,OAAAhB,EAAAlH,MAAC,KAADC,UAAA,CAgDTkI,GAanC,aAXqB,IAAI7E,QAAQ,SAACC,EAASC,GACzCyE,EAAOrE,UAAY,SAAUpC,GAC3B+B,EAAQ/B,EAAEsC,MACVmE,EAAOG,WACT,EACAH,EAAOxE,QAAU,SAAUjC,GACzBgC,EAAOhC,EAAEkC,SACTuE,EAAOG,WACT,EACAH,EAAOtE,YAAY,CAACuE,EAAsBJ,EAAOC,EAAQC,GAC3D,EAEF,GAACH,EAAA7H,MAAA,KAAAC,UAAA,C","sources":["webpack://bus/./src/data/analytics/storage-size.ts","webpack://bus/./src/data/analytics/update-rate/index.ts","webpack://bus/./src/data/analytics/bus-arrival-time/index.ts","webpack://bus/./src/data/analytics/data-usage/index.ts"],"sourcesContent":["import { convertBytes } from '../../tools/convert';\nimport { getStoresLength, lfGetItem, lfListItemKeys } from '../storage/index';\n\ninterface StoreCategory {\n  name: string;\n  key: string;\n}\n\ninterface StoreSizeInBytes {\n  category: StoreCategory;\n  size: number;\n}\n\ntype CategorizedSizesInBytes = { [key: string]: StoreSizeInBytes };\n\nexport interface StoreSize {\n  category: StoreCategory;\n  size: string;\n}\n\nexport type CategorizedSizes = { [key: string]: StoreSize };\n\nexport interface StoreSizeStatistics {\n  categorizedSizes: CategorizedSizes;\n  totalSize: number;\n}\n\nfunction storeIndexToCategory(store: number): StoreCategory {\n  const [name, key] = [\n    ['快取', 'cache'],\n    ['設定', 'settings'],\n    ['分析', 'analytics'],\n    ['分析', 'analytics'],\n    ['分析', 'analytics'],\n    ['分析', 'analytics'],\n    ['分析', 'analytics'],\n    ['個人化行程', 'personalSchedule'],\n    ['最近檢視', 'recentViews'],\n    ['通知', 'notification'],\n    ['通知', 'notification'],\n    ['資料夾', 'folders'],\n    ['資料夾', 'folders'],\n    ['資料夾', 'folders']\n  ][store] || ['其他', 'others'];\n  const result = {\n    name,\n    key\n  };\n  return result;\n}\n\nexport async function getStoresSizeStatistics(): Promise<StoreSizeStatistics> {\n  let totalSizeInBytes: number = 0;\n  const categorizedSizesInBytes: CategorizedSizesInBytes = {};\n  const storesLength = getStoresLength();\n\n  for (let i = 0; i < storesLength; i++) {\n    const keysInStore = await lfListItemKeys(i);\n    let thisStoreSizeInBytes: number = 0;\n    for (const itemKey of keysInStore) {\n      const item = await lfGetItem(i, itemKey);\n      const itemInString = String(item);\n      const itemLength = itemInString.length + itemKey.length;\n      totalSizeInBytes += itemLength;\n      thisStoreSizeInBytes += itemLength;\n    }\n    const thisCategory = storeIndexToCategory(i);\n    const thisCategoryKey = thisCategory.key;\n    if (!categorizedSizesInBytes.hasOwnProperty(thisCategoryKey)) {\n      categorizedSizesInBytes[thisCategoryKey] = {\n        category: thisCategory,\n        size: 0\n      };\n    }\n    categorizedSizesInBytes[thisCategory.key].size += thisStoreSizeInBytes;\n  }\n\n  const totalSize = convertBytes(totalSizeInBytes);\n\n  const categorizedSizes: CategorizedSizes = {};\n  for (const key in categorizedSizesInBytes) {\n    const thisCategory = categorizedSizesInBytes[key].category;\n    const thisCategorySize = categorizedSizesInBytes[key].size;\n    categorizedSizes[key] = {\n      category: thisCategory,\n      size: convertBytes(thisCategorySize)\n    };\n  }\n\n  const result: StoreSizeStatistics = {\n    totalSize,\n    categorizedSizes\n  };\n\n  return result;\n}\n","import { generateIdentifier } from '../../../tools/index';\nimport { mergePearsonCorrelation, mergeStandardDeviation } from '../../../tools/math';\nimport { EstimateTime } from '../../apis/getEstimateTime/index';\nimport { lfGetItem, lfListItemKeys, lfRemoveItem, lfSetItem } from '../../storage/index';\n\nexport type UpdateRateData = [estimateTime: number, timestamp: number]; // EstimateTime (seconds), timestamp (seconds)\n\nexport interface UpdateRateDataGroupStats {\n  estimate_time: {\n    average: number;\n    stdev: number;\n  };\n  timestamp: {\n    average: number;\n    stdev: number;\n  };\n  correlation: number;\n  length: number;\n}\n\nexport interface UpdateRateDataGroup {\n  stats: UpdateRateDataGroupStats;\n  timestamp: number;\n  id: number; // stop id\n}\n\nexport type UpdateRateDataGroupArray = Array<UpdateRateDataGroup>;\n\nexport interface UpdateRateDataWriteAheadLogGroup {\n  data: Array<UpdateRateData>;\n  timestamp: number;\n  id: string;\n}\n\nconst updateRateData_sampleQuantity: number = 32;\nlet updateRateData_trackedStops: Array<number> = [];\nlet updateRateData_writeAheadLog_id: string = '';\nlet updateRateData_writeAheadLog_tracking: boolean = false;\nlet updateRateData_writeAheadLog_currentDataLength: number = 0;\nconst updateRateData_writeAheadLog_maxDataLength: number = 45;\nlet updateRateData_writeAheadLog_group: UpdateRateDataWriteAheadLogGroup = {\n  data: {},\n  timestamp: 0,\n  id: ''\n};\nconst updateRateData_groups: Array<UpdateRateDataGroup> = [];\nconst updateRateData_groupsIndex: { [key: string]: number } = {};\n\nfunction getUpdateRateDataStats(data: Array<UpdateRateData>): UpdateRateDataGroupStats {\n  let sumEstimateTime = 0;\n  let sumEstimateTimeSquared = 0;\n  let sumTimestamp = 0;\n  let sumTimestampSquared = 0;\n  let dataLength = 0;\n  for (const item of data) {\n    const estimateTime = item[0];\n    const timestamp = item[1];\n    dataLength += 1;\n    sumEstimateTime += estimateTime;\n    sumTimestamp += timestamp;\n    sumEstimateTimeSquared += Math.pow(estimateTime, 2);\n    sumTimestampSquared += Math.pow(timestamp, 2);\n  }\n\n  const averageEstimateTime = sumEstimateTime / dataLength;\n  const averageTimestamp = sumTimestamp / dataLength;\n\n  const estimateTimeVariance = sumEstimateTimeSquared / dataLength - Math.pow(averageEstimateTime, 2);\n  const timestampVariance = sumTimestampSquared / dataLength - Math.pow(averageTimestamp, 2);\n\n  const estimateTimeSTDEV = Math.sqrt(estimateTimeVariance);\n  const timestampSTDEV = Math.sqrt(timestampVariance);\n\n  let covariance = 0;\n  for (const item2 of data) {\n    const estimateTime = item2[0];\n    const timestamp = item2[1];\n    covariance += (estimateTime - averageEstimateTime) * (timestamp - averageTimestamp);\n  }\n  covariance /= dataLength;\n\n  const correlation = covariance / (estimateTimeSTDEV * timestampSTDEV);\n\n  const result: UpdateRateDataGroupStats = {\n    estimate_time: {\n      average: averageEstimateTime,\n      stdev: estimateTimeSTDEV\n    },\n    timestamp: {\n      average: averageTimestamp,\n      stdev: timestampSTDEV\n    },\n    length: dataLength,\n    correlation: correlation\n  };\n  return result;\n}\n\nfunction mergeUpdateRateDataStats(targetStats: UpdateRateDataGroupStats, sourceStats: UpdateRateDataGroupStats): UpdateRateDataGroupStats {\n  const mergedDataLength = targetStats.length + sourceStats.length;\n\n  const mergedAverageEstimateTime = (targetStats.estimate_time.average * targetStats.length + sourceStats.estimate_time.average * sourceStats.length) / mergedDataLength;\n  const mergedAverageTimestamp = (targetStats.timestamp.average * targetStats.length + sourceStats.timestamp.average * sourceStats.length) / mergedDataLength;\n\n  const mergedEstimateTimeSTDEV = mergeStandardDeviation(targetStats.estimate_time.average, targetStats.estimate_time.stdev, targetStats.length, sourceStats.estimate_time.average, sourceStats.estimate_time.stdev, sourceStats.length);\n  const mergedTimestampSTDEV = mergeStandardDeviation(targetStats.timestamp.average, targetStats.timestamp.stdev, targetStats.length, sourceStats.timestamp.average, sourceStats.timestamp.stdev, sourceStats.length);\n\n  const mergedCorrelation = mergePearsonCorrelation(targetStats.estimate_time.average, targetStats.timestamp.average, targetStats.estimate_time.stdev, targetStats.timestamp.stdev, targetStats.length, targetStats.correlation, sourceStats.estimate_time.average, sourceStats.timestamp.average, sourceStats.estimate_time.stdev, sourceStats.timestamp.stdev, sourceStats.length, sourceStats.correlation);\n\n  const result: UpdateRateDataGroupStats = {\n    estimate_time: {\n      average: mergedAverageEstimateTime,\n      stdev: mergedEstimateTimeSTDEV\n    },\n    timestamp: {\n      average: mergedAverageTimestamp,\n      stdev: mergedTimestampSTDEV\n    },\n    length: mergedDataLength,\n    correlation: mergedCorrelation\n  };\n  return result;\n}\n\nexport async function collectUpdateRateData(EstimateTime: EstimateTime) {\n  const now = new Date();\n  const currentTimestamp: number = now.getTime();\n  let needToReset = false;\n  // Initialize\n  if (!updateRateData_writeAheadLog_tracking) {\n    updateRateData_writeAheadLog_tracking = true;\n    updateRateData_trackedStops = [];\n    updateRateData_writeAheadLog_id = generateIdentifier();\n    updateRateData_writeAheadLog_group = {\n      data: {},\n      timestamp: currentTimestamp,\n      id: updateRateData_writeAheadLog_id\n    };\n    updateRateData_writeAheadLog_currentDataLength = 0;\n    const EstimateTimeLength1: number = EstimateTime.length - 1;\n    for (let i = 0; i < updateRateData_sampleQuantity; i++) {\n      const randomIndex: number = Math.floor(Math.random() * EstimateTimeLength1);\n      const randomItem = EstimateTime[randomIndex];\n      updateRateData_trackedStops.push(randomItem.StopID);\n    }\n  }\n\n  // Record EstimateTime\n  for (const item of EstimateTime) {\n    const stopID = item.StopID;\n    const stopKey = `s_${stopID}`;\n    if (updateRateData_trackedStops.indexOf(stopID) > -1) {\n      if (!updateRateData_writeAheadLog_group.data.hasOwnProperty(stopKey)) {\n        updateRateData_writeAheadLog_group.data[stopKey] = [];\n      }\n      updateRateData_writeAheadLog_group.data[stopKey].push([parseInt(item.EstimateTime), Math.floor((currentTimestamp - updateRateData_writeAheadLog_group.timestamp) / 1000)]);\n    }\n  }\n\n  updateRateData_writeAheadLog_currentDataLength += 1;\n  if (updateRateData_writeAheadLog_currentDataLength > updateRateData_writeAheadLog_maxDataLength) {\n    needToReset = true;\n  }\n\n  if (updateRateData_writeAheadLog_currentDataLength % 5 === 0) {\n    await lfSetItem(4, updateRateData_writeAheadLog_id, JSON.stringify(updateRateData_writeAheadLog_group));\n  }\n\n  if (needToReset) {\n    for (const stopID of updateRateData_trackedStops) {\n      const stopKey = `s_${stopID}`;\n      const data = updateRateData_writeAheadLog_group.data[stopKey];\n      const dataGroup = {} as UpdateRateDataGroup;\n      const existingData = await lfGetItem(3, stopKey);\n      if (existingData) {\n        const existingDataObject = JSON.parse(existingData) as UpdateRateDataGroup;\n        dataGroup.stats = mergeUpdateRateDataStats(existingDataObject.stats, getUpdateRateDataStats(data));\n        dataGroup.timestamp = existingDataObject.timestamp;\n        dataGroup.id = stopID;\n      } else {\n        dataGroup.stats = getUpdateRateDataStats(data);\n        dataGroup.timestamp = currentTimestamp;\n        dataGroup.id = stopID;\n      }\n      await lfSetItem(3, stopKey, JSON.stringify(dataGroup));\n      if (updateRateData_groupsIndex.hasOwnProperty(stopKey)) {\n        const existingIndex = updateRateData_groupsIndex[stopKey];\n        updateRateData_groups.splice(existingIndex, 1, dataGroup);\n      } else {\n        updateRateData_groups[stopKey] = updateRateData_groups.length;\n        updateRateData_groups.push(dataGroup);\n      }\n      await lfRemoveItem(4, updateRateData_writeAheadLog_id);\n    }\n\n    updateRateData_writeAheadLog_tracking = false;\n  }\n}\n\nexport async function recoverUpdateRateDataFromWriteAheadLog() {\n  const now = new Date().getTime();\n  const oneWeekAgo = now - 60 * 60 * 7 * 1000;\n  const keys = await lfListItemKeys(4);\n  for (const key of keys) {\n    const json = await lfGetItem(4, key);\n    if (json) {\n      const object = JSON.parse(json) as UpdateRateDataWriteAheadLogGroup;\n      const thisTimestamp = object.timestamp;\n      const thisID = object.id;\n      if (thisTimestamp > oneWeekAgo) {\n        for (const stopKey in object.data) {\n          const thisStopData = object.data[stopKey];\n          const dataGroup = {} as UpdateRateDataGroup;\n          const existingData = await lfGetItem(3, stopKey);\n          if (existingData) {\n            const existingDataObject = JSON.parse(existingData) as UpdateRateDataGroup;\n            dataGroup.stats = mergeUpdateRateDataStats(existingDataObject.stats, getUpdateRateDataStats(thisStopData));\n            dataGroup.timestamp = existingDataObject.timestamp;\n            dataGroup.id = existingDataObject.id;\n          } else {\n            dataGroup.stats = getUpdateRateDataStats(thisStopData);\n            dataGroup.timestamp = thisTimestamp;\n            dataGroup.id = parseInt(stopKey.split('_')[1]);\n          }\n          await lfSetItem(3, stopKey, JSON.stringify(dataGroup));\n          if (updateRateData_groupsIndex.hasOwnProperty(stopKey)) {\n            const existingIndex = updateRateData_groupsIndex[stopKey];\n            updateRateData_groups.splice(existingIndex, 1, dataGroup);\n          } else {\n            updateRateData_groups[stopKey] = updateRateData_groups.length;\n            updateRateData_groups.push(dataGroup);\n          }\n        }\n      }\n      await lfRemoveItem(4, thisID);\n    }\n  }\n}\n\nexport async function initializeUpdateRateDataGroups() {\n  const now = new Date().getTime();\n  const oneWeekAgo = now - 60 * 60 * 7 * 1000;\n  const keys = await lfListItemKeys(3);\n  let index: number = 0;\n  for (const key of keys) {\n    const json = await lfGetItem(3, key);\n    if (json) {\n      const object = JSON.parse(json) as UpdateRateDataGroup;\n      const thisTimestamp = object.timestamp;\n      if (thisTimestamp > oneWeekAgo) {\n        updateRateData_groups.push(object);\n        updateRateData_groupsIndex[key] = index;\n        index += 1;\n      }\n    }\n  }\n}\n\nexport function listUpdateRateDataGroups(): Array<UpdateRateDataGroup> {\n  const now = new Date().getTime();\n  const oneWeekAgo = now - 60 * 60 * 7 * 1000;\n  return updateRateData_groups.filter((item) => item.timestamp > oneWeekAgo);\n}\n\nexport async function discardExpiredUpdateRateDataGroups() {\n  const now = new Date().getTime();\n  const oneWeekAgo = now - 60 * 60 * 7 * 1000;\n  const keys = await lfListItemKeys(3);\n  for (const key of keys) {\n    const json = await lfGetItem(3, key);\n    const object = JSON.parse(json) as UpdateRateDataGroup;\n    const thisTimestamp = object.timestamp;\n    if (thisTimestamp <= oneWeekAgo) {\n      await lfRemoveItem(3, key);\n    }\n  }\n}\n\nconst getUpdateRateWorkerResponses = {};\nlet port;\n\n// Check if SharedWorker is supported, and fall back to Worker if not\nif (typeof SharedWorker !== 'undefined') {\n  const getUpdateRateSharedWorker = new SharedWorker(new URL(/* webpackChunkName: \"getUpdateRate-worker\" */ './getUpdateRate-worker.ts', import.meta.url)); // Reusable shared worker\n  port = getUpdateRateSharedWorker.port; // Access the port for communication\n  port.start(); // Start the port (required by some browsers)\n} else {\n  const getUpdateRateWorker = new Worker(new URL(/* webpackChunkName: \"getUpdateRate-worker\" */ './getUpdateRate-worker.ts', import.meta.url)); // Fallback to standard worker\n  port = getUpdateRateWorker; // Use Worker directly for communication\n}\n\n// Handle messages from the worker\nport.onmessage = function (e) {\n  const [result, taskID] = e.data;\n  if (getUpdateRateWorkerResponses[taskID]) {\n    getUpdateRateWorkerResponses[taskID](result); // Resolve the correct promise\n    delete getUpdateRateWorkerResponses[taskID]; // Clean up the response handler\n  }\n};\n\n// Handle errors\nport.onerror = function (e) {\n  console.error(e.message);\n};\n\nexport async function getUpdateRate(): Promise<number> {\n  const dataGroups = await listUpdateRateDataGroups();\n  const taskID = generateIdentifier();\n\n  const result = await new Promise((resolve, reject) => {\n    getUpdateRateWorkerResponses[taskID] = resolve; // Store the resolve function for this taskID\n\n    port.onerror = function (e) {\n      reject(e.message);\n    };\n\n    port.postMessage([dataGroups, taskID]); // Send the task to the worker\n  });\n\n  return result;\n}\n","import { generateIdentifier } from '../../../tools/index';\nimport { findGlobalExtrema } from '../../../tools/math';\nimport { WeekDayIndex } from '../../../tools/time';\nimport { EstimateTime } from '../../apis/getEstimateTime/index';\nimport { listAllFolderContent } from '../../folder/index';\nimport { isInPersonalSchedule, listPersonalSchedules, PersonalSchedule } from '../../personal-schedule/index';\nimport { lfGetItem, lfListItemKeys, lfRemoveItem, lfSetItem } from '../../storage/index';\n\nconst busArrivalTimeData_writeAheadLog_maxDataLength: number = 32;\nlet busArrivalTimeData_writeAheadLog_id: string = '';\nlet busArrivalTimeData_writeAheadLog_tracking: boolean = false;\nlet busArrivalTimeData_trackedStops: Array<number> = [];\nlet busArrivalTimeData_writeAheadLog_group: BusArrivalTimeDataWriteAheadLog = {\n  data: {},\n  timestamp: 0,\n  id: ''\n};\nlet busArrivalTimeData_writeAheadLog_currentDataLength: number = 0;\n\nexport type BusArrivalTimeData = [estimateTime: number, timestamp: number]; // EstimateTime (seconds), timestamp (milliseconds)\n\nexport type BusArrivalTimeDataGroupStats = Array<number>;\n\nexport interface BusArrivalTimeDataGroup {\n  stats: BusArrivalTimeDataGroupStats;\n  day: WeekDayIndex;\n  max: number;\n  min: number;\n  timestamp: number;\n  id: number; // stop id\n}\n\nexport type BusArrivalTimeDataGroupArray = Array<BusArrivalTimeDataGroup>;\n\nexport interface BusArrivalTimeDataWriteAheadLog {\n  data: {\n    [key: string]: Array<BusArrivalTimeData>;\n  };\n  timestamp: number;\n  id: string;\n}\n\nexport interface BusArrivalTime {\n  personalSchedule: PersonalSchedule;\n  chart: string; // svg\n  day: WeekDayIndex;\n}\n\nexport interface BusArrivalTimes {\n  [stopKey: string]: Array<BusArrivalTime>;\n}\n\nconst getBusArrivalTimeDataStatsWorkerTasks = {};\nlet getBusArrivalTimeDataStatsPort;\n\n// Check if SharedWorker is supported, and fall back to Worker if not\nif (typeof SharedWorker !== 'undefined') {\n  const getBusArrivalTimeDataStatsWorker = new SharedWorker(new URL(/* webpackChunkName: \"getBusArrivalTimeDataStats-worker\" */ './getBusArrivalTimeDataStats-worker.ts', import.meta.url)); // Reusable shared worker\n  getBusArrivalTimeDataStatsPort = getBusArrivalTimeDataStatsWorker.port; // Access the port for communication\n  getBusArrivalTimeDataStatsPort.start(); // Start the port (required by some browsers)\n} else {\n  const getBusArrivalTimeDataStatsWorker = new Worker(new URL(/* webpackChunkName: \"getBusArrivalTimeDataStats-worker\" */ './getBusArrivalTimeDataStats-worker.ts', import.meta.url)); // Fallback to standard worker\n  getBusArrivalTimeDataStatsPort = getBusArrivalTimeDataStatsWorker; // Use Worker directly for communication\n}\n\n// Handle messages from the worker\ngetBusArrivalTimeDataStatsPort.onmessage = function (e) {\n  const [result, taskID] = e.data;\n  if (getBusArrivalTimeDataStatsWorkerTasks[taskID]) {\n    getBusArrivalTimeDataStatsWorkerTasks[taskID](result); // resolve\n    delete getBusArrivalTimeDataStatsWorkerTasks[taskID];\n  }\n};\n\n// Handle errors\ngetBusArrivalTimeDataStatsPort.onerror = function (e) {\n  console.error(e.message);\n};\n\nasync function getBusArrivalTimeDataStats(data: Array<BusArrivalTimeData>): Promise<BusArrivalTimeDataGroupStats> {\n  const taskID = generateIdentifier();\n\n  const result = await new Promise((resolve, reject) => {\n    getBusArrivalTimeDataStatsWorkerTasks[taskID] = resolve; // Store the resolve function for this taskID\n    getBusArrivalTimeDataStatsPort.onerror = function (e) {\n      reject(e.message);\n    };\n    getBusArrivalTimeDataStatsPort.postMessage([data, taskID]); // Send the task to the worker\n  });\n  return result;\n}\n\nfunction mergeBusArrivalTimeDataStats(targetStats: BusArrivalTimeDataGroupStats, sourceStats: BusArrivalTimeDataGroupStats): BusArrivalTimeDataGroupStats {\n  const mergedArray = new Uint32Array(60 * 24);\n  for (let i = 60 * 24 - 1; i >= 0; i--) {\n    mergedArray[i] = targetStats[i] + sourceStats[i];\n  }\n  return Array.from(mergedArray);\n}\n\nexport async function collectBusArrivalTimeData(EstimateTime: EstimateTime) {\n  const now = new Date();\n  const currentTimestamp: number = now.getTime();\n  const currentDay = now.getDay();\n  let needToReset = false;\n  // Initialize\n  if (!busArrivalTimeData_writeAheadLog_tracking) {\n    busArrivalTimeData_writeAheadLog_tracking = true;\n    busArrivalTimeData_writeAheadLog_id = generateIdentifier();\n    busArrivalTimeData_writeAheadLog_group = {\n      id: busArrivalTimeData_writeAheadLog_id,\n      timestamp: currentTimestamp,\n      data: {}\n    };\n    busArrivalTimeData_writeAheadLog_currentDataLength = 0;\n    const allFolderContent = await listAllFolderContent(['stop']);\n    busArrivalTimeData_trackedStops = allFolderContent.map((e) => e.id);\n  }\n\n  // Record EstimateTime\n  if (isInPersonalSchedule(now)) {\n    for (const item of EstimateTime) {\n      const stopID = item.StopID;\n      const stopKey = `s_${stopID}_${currentDay}`;\n      if (busArrivalTimeData_trackedStops.indexOf(stopID) > -1) {\n        if (!busArrivalTimeData_writeAheadLog_group.data.hasOwnProperty(stopKey)) {\n          busArrivalTimeData_writeAheadLog_group.data[stopKey] = [];\n        }\n        busArrivalTimeData_writeAheadLog_group.data[stopKey].push([parseInt(item.EstimateTime), currentTimestamp]);\n      }\n    }\n\n    busArrivalTimeData_writeAheadLog_currentDataLength += 1;\n    if (busArrivalTimeData_writeAheadLog_currentDataLength > busArrivalTimeData_writeAheadLog_maxDataLength) {\n      needToReset = true;\n    }\n\n    if (needToReset || busArrivalTimeData_writeAheadLog_currentDataLength % 8 === 0) {\n      await lfSetItem(5, busArrivalTimeData_writeAheadLog_id, JSON.stringify(busArrivalTimeData_writeAheadLog_group));\n    }\n\n    if (needToReset) {\n      for (const stopID of busArrivalTimeData_trackedStops) {\n        const stopKey = `s_${stopID}_${currentDay}`;\n        const data = busArrivalTimeData_writeAheadLog_group.data[stopKey];\n        const dataGroup = {} as BusArrivalTimeDataGroup;\n        const existingData = await lfGetItem(6, stopKey);\n        if (existingData) {\n          const existingDataObject = JSON.parse(existingData) as BusArrivalTimeDataGroup;\n          const newStats = getBusArrivalTimeDataStats(data);\n          const mergedStats = mergeBusArrivalTimeDataStats(existingDataObject.stats, newStats);\n          dataGroup.stats = mergedStats;\n          const mergedExtrema = findGlobalExtrema(mergedStats);\n          dataGroup.min = mergedExtrema[0];\n          dataGroup.max = mergedExtrema[1];\n          dataGroup.day = currentDay;\n          dataGroup.timestamp = existingDataObject.timestamp;\n          dataGroup.id = stopID;\n        } else {\n          const newStats = getBusArrivalTimeDataStats(data);\n          dataGroup.stats = newStats;\n          const newExtrema = findGlobalExtrema(newStats);\n          dataGroup.min = newExtrema[0];\n          dataGroup.max = newExtrema[1];\n          dataGroup.day = currentDay;\n          dataGroup.timestamp = currentTimestamp;\n          dataGroup.id = stopID;\n        }\n        await lfSetItem(6, stopKey, JSON.stringify(dataGroup));\n        await lfRemoveItem(5, busArrivalTimeData_writeAheadLog_id);\n      }\n      busArrivalTimeData_writeAheadLog_tracking = false;\n    }\n  }\n}\n\nexport async function recoverBusArrivalTimeDataFromWriteAheadLog() {\n  const now = new Date();\n  const currentTimestamp = now.getTime();\n  const currentDay = now.getDay();\n  const keys = await lfListItemKeys(5);\n  for (const key of keys) {\n    const json = await lfGetItem(5, key);\n    const object = JSON.parse(json) as BusArrivalTimeDataWriteAheadLog;\n    const thisID = object.id;\n    for (const stopKey in object.data) {\n      const thisStopData = object.data[stopKey];\n      const dataGroup = {} as BusArrivalTimeDataGroup;\n      const existingData = await lfGetItem(6, stopKey);\n      const stopID = parseInt(stopKey.split('_')[1]);\n      if (existingData) {\n        const existingDataObject = JSON.parse(existingData) as BusArrivalTimeDataGroup;\n        const newStats = getBusArrivalTimeDataStats(thisStopData);\n        const mergedStats = mergeBusArrivalTimeDataStats(existingDataObject.stats, newStats);\n        dataGroup.stats = mergedStats;\n        const newExtremum = findGlobalExtrema(mergedStats);\n        dataGroup.min = newExtremum[0];\n        dataGroup.max = newExtremum[1];\n        dataGroup.day = existingDataObject.day;\n        dataGroup.timestamp = existingDataObject.timestamp;\n        dataGroup.id = stopID;\n      } else {\n        const newStats = getBusArrivalTimeDataStats(thisStopData);\n        dataGroup.stats = newStats;\n        const newExtremum = findGlobalExtrema(newStats);\n        dataGroup.min = newExtremum[0];\n        dataGroup.max = newExtremum[1];\n        dataGroup.day = currentDay;\n        dataGroup.timestamp = currentTimestamp;\n        dataGroup.id = stopID;\n      }\n      await lfSetItem(6, stopKey, JSON.stringify(dataGroup));\n    }\n    await lfRemoveItem(5, thisID);\n  }\n}\n\nexport async function listBusArrivalTimeDataGroups(): Promise<BusArrivalTimeDataGroupArray> {\n  const keys = await lfListItemKeys(6);\n  const result: BusArrivalTimeDataGroupArray = [];\n  for (const key of keys) {\n    const json = await lfGetItem(6, key);\n    if (json) {\n      const object = JSON.parse(json) as BusArrivalTimeDataGroup;\n      result.push(object);\n    }\n  }\n  return result;\n}\n\nconst getBusArrivalTimesWorkerResponses = {};\nlet getBusArrivalTimesPort;\n\n// Check if SharedWorker is supported, and fall back to Worker if not\nif (typeof SharedWorker !== 'undefined') {\n  const getUpdateRateSharedWorker = new SharedWorker(new URL('./getBusArrivalTimes-worker.ts', import.meta.url)); // Reusable shared worker\n  getBusArrivalTimesPort = getUpdateRateSharedWorker.port; // Access the port for communication\n  getBusArrivalTimesPort.start(); // Start the port (required by some browsers)\n} else {\n  const getUpdateRateWorker = new Worker(new URL('./getBusArrivalTimes-worker.ts', import.meta.url)); // Fallback to standard worker\n  getBusArrivalTimesPort = getUpdateRateWorker; // Use Worker directly for communication\n}\n\n// Handle messages from the worker\ngetBusArrivalTimesPort.onmessage = function (e) {\n  const [result, taskID] = e.data;\n  if (getBusArrivalTimesWorkerResponses[taskID]) {\n    getBusArrivalTimesWorkerResponses[taskID](result); // Resolve the correct promise\n    delete getBusArrivalTimesWorkerResponses[taskID]; // Clean up the response handler\n  }\n};\n\n// Handle errors\ngetBusArrivalTimesPort.onerror = function (e) {\n  console.error(e.message);\n};\n\nexport async function getBusArrivalTimes(chartWidth: number, chartHeight: number): Promise<BusArrivalTimes> {\n  const taskID = generateIdentifier();\n\n  const personalSchedules = await listPersonalSchedules();\n  const busArrivalTimeDataGroups = await listBusArrivalTimeDataGroups();\n\n  const result = await new Promise((resolve, reject) => {\n    getBusArrivalTimesWorkerResponses[taskID] = resolve; // Store the resolve function for this taskID\n    getBusArrivalTimesPort.onerror = function (e) {\n      reject(e.message);\n    };\n    getBusArrivalTimesPort.postMessage([personalSchedules, busArrivalTimeDataGroups, chartWidth, chartHeight, taskID]); // Send the task to the worker\n  });\n  return result;\n}\n","import { createDateObjectFromDate, dateToString, offsetDate, TimeStampPeriod } from '../../../tools/time';\nimport { lfGetItem, lfListItemKeys, lfRemoveItem, lfSetItem } from '../../storage/index';\n\nexport interface DataUsageStatsChunk {\n  date: [year: number, month: number, day: number];\n  data: Array<number>;\n  stats: {\n    sum: number;\n    max: number;\n    min: number;\n  };\n}\n\nexport type DataUsageStatsChunkArray = Array<DataUsageStatsChunk>;\n\nexport interface DataUsageStats {\n  stats: {\n    sum: number;\n    max: number;\n    min: number;\n  };\n  period: TimeStampPeriod;\n  chart: string;\n}\n\nexport const DataUsagePeriod = 7; // days\n\nexport async function recordDataUsage(contentLength: number, date: Date) {\n  const key = `d_${dateToString(date, 'YYYY_MM_DD')}`;\n  const hours = date.getHours();\n  const minutes = date.getMinutes();\n  const index = hours * 60 + minutes;\n  const existingDataUsageStatsChunkJSON = await lfGetItem(2, key);\n  if (existingDataUsageStatsChunkJSON) {\n    const existingDataUsageStatsChunkObject = JSON.parse(existingDataUsageStatsChunkJSON) as DataUsageStatsChunk;\n    existingDataUsageStatsChunkObject.stats.sum += contentLength;\n    existingDataUsageStatsChunkObject.data[index] += contentLength;\n    const changedData = existingDataUsageStatsChunkObject.data[index];\n    if (changedData > existingDataUsageStatsChunkObject.stats.max) {\n      existingDataUsageStatsChunkObject.stats.max = changedData;\n    }\n    if (changedData < existingDataUsageStatsChunkObject.stats.min) {\n      existingDataUsageStatsChunkObject.stats.min = changedData;\n    }\n    await lfSetItem(2, key, JSON.stringify(existingDataUsageStatsChunkObject));\n  } else {\n    const newDataUsageStatsChunk = {} as DataUsageStatsChunk;\n    const data = new Uint32Array(60 * 24);\n    data[index] += contentLength;\n    newDataUsageStatsChunk.data = Array.from(data);\n    newDataUsageStatsChunk.stats = {\n      sum: contentLength,\n      max: contentLength,\n      min: 0\n    };\n    newDataUsageStatsChunk.date = [date.getFullYear(), date.getMonth() + 1, date.getDate()];\n    await lfSetItem(2, key, JSON.stringify(newDataUsageStatsChunk));\n  }\n}\n\nexport async function listDataUsageStatsChunks(): Promise<DataUsageStatsChunkArray> {\n  const endDate = new Date();\n  endDate.setHours(0);\n  endDate.setMinutes(0);\n  endDate.setSeconds(0);\n  endDate.setMilliseconds(0);\n  const startDate = offsetDate(endDate, -1 * DataUsagePeriod, 0, 0);\n  const result: DataUsageStatsChunkArray = [];\n  for (let i = 1; i <= DataUsagePeriod; i++) {\n    const date = offsetDate(startDate, i, 0, 0);\n    const key = `d_${dateToString(date, 'YYYY_MM_DD')}`;\n    const existingDataUsageStatsChunkJSON = await lfGetItem(2, key);\n    if (existingDataUsageStatsChunkJSON) {\n      const existingDataUsageStatsChunkObject = JSON.parse(existingDataUsageStatsChunkJSON) as DataUsageStatsChunk;\n      result.push(existingDataUsageStatsChunkObject);\n    } else {\n      const blankDataUsageStatsChunk = {} as DataUsageStatsChunk;\n      const data = new Uint32Array(60 * 24);\n      blankDataUsageStatsChunk.data = Array.from(data);\n      blankDataUsageStatsChunk.stats = {\n        sum: 0,\n        max: 0,\n        min: 0\n      };\n      blankDataUsageStatsChunk.date = [date.getFullYear(), date.getMonth() + 1, date.getDate()];\n      result.push(blankDataUsageStatsChunk);\n    }\n  }\n  return result;\n}\n\nexport async function discardExpiredDataUsageStats() {\n  const millisecondsPerDay = 60 * 60 * 24 * 1000;\n  const expirationPeriod = millisecondsPerDay * DataUsagePeriod;\n  const now = new Date().getTime();\n  const keys = await lfListItemKeys(2);\n  for (const key of keys) {\n    const json = await lfGetItem(2, key);\n    const object = JSON.parse(json) as DataUsageStatsChunk;\n    const date = createDateObjectFromDate(object.date[0], object.date[1], object.date[2]);\n    if (now - date.getTime() > expirationPeriod) {\n      await lfRemoveItem(2, key);\n    }\n  }\n}\n\nexport async function getDataUsageStats(width: number, height: number, padding: number): Promise<DataUsageStats> {\n  const worker = new Worker(new URL(/* webpackChunkName: \"getDataUsageStats-worker\" */ './getDataUsageStats-worker.ts', import.meta.url));\n  const dataUsageStatsChunks = await listDataUsageStatsChunks();\n  // Wrap worker communication in a promise\n  const result = await new Promise((resolve, reject) => {\n    worker.onmessage = function (e) {\n      resolve(e.data); // Resolve the promise with the worker's result\n      worker.terminate(); // Terminate the worker when done\n    };\n    worker.onerror = function (e) {\n      reject(e.message); // Reject the promise on error\n      worker.terminate(); // Terminate the worker if an error occurs\n    };\n    worker.postMessage([dataUsageStatsChunks, width, height, padding]); // Send data to the worker\n  });\n  return result;\n}\n"],"names":["storeIndexToCategory","store","_ref","_ref2","_slicedToArray","name","key","getStoresSizeStatistics","_getStoresSizeStatistics","apply","arguments","_asyncToGenerator","totalSizeInBytes","categorizedSizesInBytes","storesLength","getStoresLength","i","_step","thisStoreSizeInBytes","_iterator","_createForOfIteratorHelper","lfListItemKeys","s","n","done","itemKey","value","item","lfGetItem","itemLength","String","length","err","e","f","thisCategory","thisCategoryKey","hasOwnProperty","category","size","totalSize","convertBytes","categorizedSizes","thisCategorySize","updateRateData_groups","port","getUpdateRateWorkerResponses","SharedWorker","getUpdateRateSharedWorker","URL","start","getUpdateRateWorker","Worker","getUpdateRate","_getUpdateRate","oneWeekAgo","dataGroups","Date","getTime","filter","timestamp","taskID","generateIdentifier","Promise","resolve","reject","onerror","message","postMessage","onmessage","_e$data","data","result","getBusArrivalTimeDataStatsPort","getBusArrivalTimeDataStatsWorkerTasks","getBusArrivalTimeDataStatsWorker","_listBusArrivalTimeDataGroups","_step4","_iterator4","json","object","JSON","parse","push","getBusArrivalTimesPort","getBusArrivalTimesWorkerResponses","getBusArrivalTimes","_x3","_x4","_getBusArrivalTimes","chartWidth","chartHeight","personalSchedules","listPersonalSchedules","busArrivalTimeDataGroups","listBusArrivalTimeDataGroups","_e$data2","recordDataUsage","_x","_x2","_recordDataUsage","contentLength","date","dateToString","index","getHours","getMinutes","existingDataUsageStatsChunkJSON","existingDataUsageStatsChunkObject","stats","sum","changedData","max","min","lfSetItem","stringify","newDataUsageStatsChunk","Uint32Array","Array","from","getFullYear","getMonth","getDate","_listDataUsageStatsChunks","endDate","setHours","setMinutes","setSeconds","setMilliseconds","startDate","offsetDate","blankDataUsageStatsChunk","getDataUsageStats","_x5","_getDataUsageStats","width","height","padding","worker","dataUsageStatsChunks","listDataUsageStatsChunks","terminate"],"ignoreList":[],"sourceRoot":""}